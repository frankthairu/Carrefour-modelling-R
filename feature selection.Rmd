---
title: "Untitled"
author: "Francis Thairu"
date: '2022-03-29'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
path<-"http://bit.ly/FeatureSelectionDataset"
Dataset<-read.csv(path, sep = ",", dec = ".",row.names = 1)
Dataset<-Dataset[-4] 
head(Dataset,3)
```
```{r}
library(caret)
```

```{r}
# Installing and loading the corrplot package for plotting
# ---
# 
suppressWarnings(
        suppressMessages(if
                         (!require(corrplot, quietly=TRUE))
                install.packages("corrplot")))
library(corrplot)
```

```{r}
# Calculating the correlation matrix
# ---
#
correlationMatrix <- cor(Dataset)
```

```{r}
 # Find attributes that are highly correlated
# ---
#
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
```

```{r}
# Highly correlated attributes
# ---
# 
highlyCorrelated

names(Dataset[,highlyCorrelated])
```
```{r}

# We can remove the variables with a higher correlation 
# and comparing the results graphically as shown below
# ---
# 
# Removing Redundant Features 
# ---
# 
Dataset2<-Dataset[-highlyCorrelated]

# Performing our graphical comparison
# ---
# 
par(mfrow = c(1, 2))
corrplot(correlationMatrix, order = "hclust")
corrplot(cor(Dataset2), order = "hclust")
```

## Wrapper method
```{r}
# We use the clustvarsel package that contains an implementation of wrapper methods. 
# The clustvarsel function will implement variable section methodology 
# for model-based clustering to find the optimal subset of variables in a dataset.
# ---
# OUR CODE GOES BELOW
# 

# Loading data from our csv file
# ---
#
path<-"http://bit.ly/FeatureSelectionDataset2" 
Dataset<-read.csv(path, sep = ",", dec = ".",row.names = 1)
head(Dataset)
```
```{r}
suppressWarnings(
        suppressMessages(if
                         (!require(clustvarsel, quietly=TRUE))
                install.packages("clustvarsel")))
                         
library(clustvarsel)
```

```{r}
# Installing and loading our mclust package
# ---
# 
suppressWarnings(
        suppressMessages(if
                         (!require(mclust, quietly=TRUE))
                install.packages("mclust")))
library(mclust)
```

```{r}
# Sequential forward greedy search (default)
# ---
#
out = clustvarsel(Dataset, G = 1:5)
out
```

```{r}
# The selection algorithm would indicate that the subset 
# we use for the clustering model is composed of variables X1 and X2 
# and that other variables should be rejected. 
# Having identified the variables that we use, we proceed to build the clustering model:
# ---
#

Subset1 = Dataset[,out$subset]
mod = Mclust(Subset1, G = 1:5)
summary(mod)
```


```{r}
plot(mod,c("classification"))


```

## embeded method

```{r}
# We will use the ewkm function from the wskm package.
# This is a weighted subspace clustering algorithm that is well suited to very high dimensional data.
# ---
# OUR CODE GOES BELOW
# 

# We install and load our wskm package
# ---
#
suppressWarnings(
        suppressMessages(if
                         (!require(wskm, quietly=TRUE))
                install.packages("wskm")))
library(wskm)

set.seed(2)
model <- ewkm(iris[1:4], 3, lambda=2, maxiter=1000)

```

```{r}
# Loading and installing our cluster package
# ---
#
suppressWarnings(
        suppressMessages(if
                         (!require(cluster, quietly=TRUE))
                install.packages("cluster")))
library("cluster")

# Cluster Plot against 1st 2 principal components
# ---
#
clusplot(iris[1:4], model$cluster, color=TRUE, shade=TRUE,
         labels=2, lines=1,main='Cluster Analysis for Iris')

```

```{r}
# Weights are calculated for each variable and cluster. 
# They are a measure of the relative importance of each variable 
# with regards to the membership of the observations to that cluster. 
# The weights are incorporated into the distance function, 
# typically reducing the distance for more important variables.
# Weights remain stored in the model and we can check them as follows:
# 
round(model$weights*100,2)
```

## Feature Ranking

```{r}
# Example 4: Feature Ranking
# ---
# We will use the FSelector Package. This is a package containing functions for selecting attributes from a given dataset. 
# ---
# OUR CODE GOES BELOW
# 

# We install and load the required packages
# ---
# 
suppressWarnings(
        suppressMessages(if
                         (!require(FSelector, quietly=TRUE))
                install.packages("FSelector")))
library(FSelector)
```

```{r}
# Loading our dataset 
# ---
#
path<-"http://bit.ly/FeatureSelectionDataset" 
Dataset<-read.csv(path, sep = ",", dec = ".",row.names = 1)

Dataset<-Dataset[-4] 
str(Dataset)
head(Dataset)

```

